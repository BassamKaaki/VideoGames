{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression (Kristin)\n",
    "1.  Model #1: default parameters\n",
    "2.  Model #2:  add max_sample_leafs\n",
    "3.  Model #3:  increase n_estimators and decrease max_sample_leafs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "vgsales = pd.read_excel('vgsales_v5.xlsx')\n",
    "\n",
    "vgsales.head()\n",
    "\n",
    "# Create dummy variables for | Genre | First_Party | Platform_Type\n",
    "\n",
    "#dummy variables for Genre\n",
    "dummy_genre = pd.get_dummies(vgsales.Genre)\n",
    "dummy_genre\n",
    "\n",
    "#dummy variables for First Party\n",
    "dummy_first_party = pd.get_dummies(vgsales.First_Party)\n",
    "dummy_first_party\n",
    "\n",
    "#dummy variables for Platform Type\n",
    "dummy_platform_type = pd.get_dummies(vgsales.Platform_Type)\n",
    "dummy_platform_type\n",
    "\n",
    "#Merge dummy frames into one dataset with original vgsales datframe\n",
    "merged_vgsales = pd.concat([vgsales, dummy_genre, dummy_first_party, dummy_platform_type], axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgsales_df = pd.DataFrame(merged_vgsales)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Rank (it is perfectly correlated with sales because it is based on global sales & is a result of sales\n",
    "# drop Name (a significant number of dummy variables would have to be created and we are not analyzing the impact of name, but trying to understand impact of genre, platform and region on sales)\n",
    "#drop Platform (we have created Platform Type and First Parties categories that are more meaningful than Platform)\n",
    "#drop Publisher (similar reason as Name)\n",
    "\n",
    "vgsales_df2 = vgsales_df.drop(columns = [\"Rank\",\"Name\", \"Platform\", \"Publisher\",\"Genre\", \"First_Party\", \"Platform_Type\",\"Year_1_Sales\", \"Year\", \"Atari\",\"SEGA\", \"Other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X, y\n",
    "\n",
    "X = vgsales_df2.drop(columns = \"Global_Sales\")\n",
    "y = vgsales_df2.Global_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12783, 24)\n",
      "(12783,)\n",
      "(1598, 24)\n",
      "(1598,)\n",
      "(1598, 24)\n",
      "(1598,)\n"
     ]
    }
   ],
   "source": [
    "#create test/train/validation sets, 80% = train, 10% = test, 10% = validation\n",
    "#check shape to ensure similar sizes \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timeit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.07703087593867343\n",
      "rmse: 0.27754436751386874\n",
      "r-squared: 0.962614931388856\n",
      "training time: 0.008365099999998904\n"
     ]
    }
   ],
   "source": [
    "#Model #1:  using default parameters, except i set n_estimators to 100 to avoid pink error\n",
    "\n",
    "rnd_reg1 = RandomForestRegressor(n_estimators = 100)\n",
    "rnd_reg1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf1 = rnd_reg1.predict(X_val)\n",
    "print(\"mse:\",mean_squared_error(y_val, y_pred_rf1))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_val, y_pred_rf1)))\n",
    "print(\"r-squared:\", r2_score(y_val, y_pred_rf1))\n",
    "print(\"training time:\", timeit.timeit())\n",
    "\n",
    "#good results, low rmse and hight r-squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.14491438981596322\n",
      "rmse: 0.380676227017085\n",
      "r-squared: 0.9296693132462236\n",
      "training time: 0.00779339999999884\n"
     ]
    }
   ],
   "source": [
    "#Model #2:  keep n_estimators at 100, set max_leaf_nodes to 16\n",
    "\n",
    "rnd_reg2 = RandomForestRegressor(n_estimators = 100, max_leaf_nodes = 16)\n",
    "rnd_reg2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf2 = rnd_reg2.predict(X_val)\n",
    "print(\"mse:\",mean_squared_error(y_val, y_pred_rf2))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_val, y_pred_rf2)))\n",
    "print(\"r-squared:\", r2_score(y_val, y_pred_rf2))\n",
    "print(\"training time:\", timeit.timeit())\n",
    "\n",
    "#good results, but not as good as #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.31576435324966223\n",
      "rmse: 0.561929135434053\n",
      "r-squared: 0.8467514244471225\n",
      "training time: 0.010345100000000329\n"
     ]
    }
   ],
   "source": [
    "#Model #3:   n_estimators at 500 and max_leaf_nodes to 5\n",
    "\n",
    "rnd_reg3 = RandomForestRegressor(n_estimators = 500, max_leaf_nodes = 5)\n",
    "rnd_reg3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf3 = rnd_reg3.predict(X_val)\n",
    "print(\"mse:\",mean_squared_error(y_val, y_pred_rf3))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_val, y_pred_rf3)))\n",
    "print(\"r-squared:\", r2_score(y_val, y_pred_rf3))\n",
    "print(\"training time:\", timeit.timeit())\n",
    "\n",
    "#slower than other models and the worst results, stick with model 1, default parameters with n_estimators set to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Training Score: 1.00 \n",
      "OOB Score: 0.97 \n",
      "R^2 Validation Score: 0.97\n",
      "mse: 0.06201651093241559\n",
      "rmse: 0.2490311445028826\n",
      "r-squared: 0.9699017895359526\n",
      "training time: 0.03561089999999467\n"
     ]
    }
   ],
   "source": [
    "#run random forest based on article https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e\n",
    "\n",
    "rf4 = RandomForestRegressor(n_estimators = 100,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "rf4.fit(X_train, y_train)\n",
    "\n",
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf4.score(X_train, y_train), \n",
    "                                                                                             rf4.oob_score_,\n",
    "                                                                                             rf4.score(X_val, y_val)))\n",
    "y_pred_rf4 = rf4.predict(X_val)\n",
    "print(\"mse:\",mean_squared_error(y_val, y_pred_rf4))\n",
    "print(\"rmse:\", sqrt(mean_squared_error(y_val, y_pred_rf4)))\n",
    "print(\"r-squared:\", r2_score(y_val, y_pred_rf4))\n",
    "print(\"training time:\", timeit.timeit())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>8.646040e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>1.116441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>JP_Sales</td>\n",
       "      <td>4.457265e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Avg_Annual_Sales</td>\n",
       "      <td>3.922871e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Other_Sales</td>\n",
       "      <td>6.213028e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Years_In_Market</td>\n",
       "      <td>4.926145e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Nintendo</td>\n",
       "      <td>7.855709e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Console</td>\n",
       "      <td>1.023527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sony</td>\n",
       "      <td>7.687196e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HH</td>\n",
       "      <td>7.287260e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Simulation</td>\n",
       "      <td>5.288058e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>4.508447e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shooter</td>\n",
       "      <td>2.436861e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fighting</td>\n",
       "      <td>1.248836e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Racing</td>\n",
       "      <td>1.111609e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sports</td>\n",
       "      <td>5.940512e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Puzzle</td>\n",
       "      <td>5.794752e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Microsoft</td>\n",
       "      <td>3.912842e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Strategy</td>\n",
       "      <td>9.758527e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Action</td>\n",
       "      <td>7.859644e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Adventure</td>\n",
       "      <td>3.050768e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PC</td>\n",
       "      <td>-4.616427e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PC</td>\n",
       "      <td>-6.195398e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Misc</td>\n",
       "      <td>-9.510291e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Importance\n",
       "Feature                       \n",
       "NA_Sales          8.646040e-01\n",
       "EU_Sales          1.116441e-01\n",
       "JP_Sales          4.457265e-02\n",
       "Avg_Annual_Sales  3.922871e-02\n",
       "Other_Sales       6.213028e-03\n",
       "Years_In_Market   4.926145e-03\n",
       "Nintendo          7.855709e-04\n",
       "Console           1.023527e-04\n",
       "Sony              7.687196e-05\n",
       "HH                7.287260e-05\n",
       "Simulation        5.288058e-05\n",
       "Role-Playing      4.508447e-05\n",
       "Shooter           2.436861e-05\n",
       "Fighting          1.248836e-05\n",
       "Racing            1.111609e-05\n",
       "Sports            5.940512e-06\n",
       "Puzzle            5.794752e-06\n",
       "Microsoft         3.912842e-06\n",
       "Strategy          9.758527e-07\n",
       "Action            7.859644e-07\n",
       "Adventure         3.050768e-07\n",
       "PC               -4.616427e-06\n",
       "PC               -6.195398e-06\n",
       "Misc             -9.510291e-06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permutation importances\n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "def r2(rf4, X_train, y_train):\n",
    "    return r2_score(y_train, rf4.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf4, X_train, y_train, r2)\n",
    "\n",
    "perm_imp_rfpimp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.ensembles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-df4e2b4e405d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensembles\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgsales_df2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Global_Sales\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.ensembles'"
     ]
    }
   ],
   "source": [
    "#the example in book uses classification, need to change the below to regression\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensembles import ExtraTreesRegressor\n",
    "\n",
    "labels = vgsales_df2.drop(columns = [\"Global_Sales\"])\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X_train, y_train = make_classification(n_samples=1000,\n",
    "                           n_features=10,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=0,\n",
    "                           shuffle=False)\n",
    "\n",
    "# Build a forest and compute the impurity-based feature importances\n",
    "forest = ExtraTreesRegressor(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
